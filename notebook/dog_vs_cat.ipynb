{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测python版本\n",
    "这里我们使用的python的版本为3.6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "为了更好的训练模型，这里对数据进行一定程度对预处理\n",
    "- 删除训练数据集中过大（`500*500`以上）和过小（`100*100`以下）的图片。\n",
    "- 将图片按照一定的目录结构归类。\n",
    "- 删除错误标记的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from PIL import Image\n",
    "\n",
    "# 删除被错误标记的图片\n",
    "def pick_err_flag(path, bad_path):\n",
    "\n",
    "    # 没有目录，补充创建\n",
    "    if not os.path.isdir(bad_path):\n",
    "        os.mkdir(bad_path)\n",
    "    \n",
    "    bad_list = ['cat.92.jpg',    'cat.724.jpg',   'cat.1450.jpg',  'cat.3216.jpg', 'cat.3822.jpg', 'cat.5351.jpg',\n",
    "                'cat.5418.jpg',  'cat.7377.jpg',  'cat.7564.jpg',  'cat.8456.jpg', 'cat.9171.jpg', 'cat.10029.jpg',\n",
    "                'cat.10712.jpg', 'cat.11184.jpg', 'dog.1259.jpg',  'dog.1835.jpg', 'dog.2614.jpg', 'dog.3889.jpg',\n",
    "                'dog.4367.jpg',  'dog.5604.jpg',  'dog.8736.jpg',  'dog.8898.jpg', 'dog.9517.jpg', 'dog.10161.jpg',\n",
    "                'dog.10190.jpg', 'dog.10237.jpg', 'dog.10401.jpg', 'dog.10797.jpg','dog.10801.jpg','dog.11186.jpg',\n",
    "                'dog.11299.jpg', 'dog.12376.jpg', 'dog.10747.jpg']\n",
    "    for img_name in bad_list:\n",
    "        im_path = os.path.join(path, img_name)\n",
    "        if os.path.exists(im_path):\n",
    "            shutil.move(im_path, os.path.join(bad_path, img_name))\n",
    "    print(len(bad_list))\n",
    "\n",
    "pick_err_flag(\"data/train\", \"data/train_bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 删除不合尺寸\n",
    "def pick_bad_pics(path, bad_path):\n",
    "\n",
    "    # 没有目录，补充创建\n",
    "    if not os.path.isdir(bad_path):\n",
    "        os.mkdir(bad_path)\n",
    "    \n",
    "    bad_list = []\n",
    "    img_list = os.listdir(path)\n",
    "    for img_name in img_list:\n",
    "        im_path = os.path.join(path, img_name)\n",
    "        im = Image.open(im_path)\n",
    "        w, h = im.size\n",
    "        if w > 500 or h > 500 or w < 10 or h < 10:\n",
    "            bad_list.append(img_name)\n",
    "            shutil.move(im_path, os.path.join(bad_path, img_name))\n",
    "    print(len(bad_list))\n",
    "\n",
    "pick_bad_pics(\"data/train\", \"data/train_bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取加载数据集，归一化处理\n",
    "将用于训练的数据集加载到内存，等待处理。主要是转化为ndarray类型到数据，方便后续到计算和处理.因为选择到预训练模型，对于图片到要求都是`299*299`大小，这里我们读取数据时，图片统一调整到这个尺寸。\n",
    "- 加载训练集数据。\n",
    "- 加载测试集数据。\n",
    "- 输出一个经过正规化的、Numpy array 格式的图像数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 加载训练集\n",
    "def load_train_data():\n",
    "\n",
    "    cat = glob.glob(\"data/train/cat.*.jpg\")\n",
    "    dog = glob.glob(\"data/train/dog.*.jpg\")\n",
    "    train_data = np.zeros(((len(cat)+len(dog)), 299, 299, 3), dtype=np.uint8)\n",
    "    train_targ = np.array([0]*len(cat) + [1]*len(dog))\n",
    "\n",
    "    i = 0\n",
    "    for img_name in tqdm(cat):\n",
    "        img = cv2.imread(img_name)\n",
    "        train_data[i] = cv2.resize(img,(299, 299))\n",
    "        i += 1\n",
    "    for img_name in tqdm(dog):\n",
    "        img = cv2.imread(img_name)\n",
    "        train_data[i] = cv2.resize(img,(299, 299))\n",
    "        i += 1\n",
    "\n",
    "    return train_data, train_targ\n",
    "\n",
    "# 加载测试集\n",
    "def load_test_data():\n",
    "\n",
    "    test = glob.glob(\"data/test/*.jpg\")\n",
    "    test_data = np.zeros((len(test), 299, 299, 3), dtype=np.uint8)\n",
    "\n",
    "    for img_name in tqdm(test):\n",
    "        index = int(img_name[img_name.rfind('/')+1:img_name.rfind('.')])\n",
    "        #print(\"index=%d name=%s\" % (index, img_name))\n",
    "        img = cv2.imread(img_name)\n",
    "        test_data[index-1] = cv2.resize(img,(299, 299))\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12485/12485 [00:38<00:00, 322.10it/s]\n",
      "100%|██████████| 12480/12480 [00:39<00:00, 313.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# 处理，加载训练集数据\n",
    "train_data, train_targ = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12500 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 30/12500 [00:00<00:43, 288.31it/s]\u001b[A\n",
      "  0%|          | 55/12500 [00:00<00:46, 264.84it/s]\u001b[A\n",
      "  1%|          | 84/12500 [00:00<00:45, 270.85it/s]\u001b[A\n",
      "  1%|          | 110/12500 [00:00<00:46, 267.05it/s]\u001b[A\n",
      "  1%|          | 141/12500 [00:00<00:45, 273.46it/s]\u001b[A\n",
      "  1%|▏         | 169/12500 [00:00<00:44, 274.42it/s]\u001b[A\n",
      "  2%|▏         | 194/12500 [00:00<00:45, 270.75it/s]\u001b[A\n",
      "  2%|▏         | 220/12500 [00:00<00:45, 269.39it/s]\u001b[A\n",
      "  2%|▏         | 250/12500 [00:00<00:45, 271.99it/s]\u001b[A\n",
      "  2%|▏         | 279/12500 [00:01<00:44, 273.67it/s]\u001b[A\n",
      "  2%|▏         | 310/12500 [00:01<00:44, 276.68it/s]\u001b[A\n",
      "  3%|▎         | 339/12500 [00:01<00:43, 277.70it/s]\u001b[A\n",
      "  3%|▎         | 368/12500 [00:01<00:43, 276.43it/s]\u001b[A\n",
      "  3%|▎         | 396/12500 [00:01<00:43, 275.58it/s]\u001b[A\n",
      "  3%|▎         | 424/12500 [00:01<00:43, 275.56it/s]\u001b[A\n",
      "  4%|▎         | 452/12500 [00:01<00:43, 274.92it/s]\u001b[A\n",
      "  4%|▍         | 481/12500 [00:01<00:43, 275.57it/s]\u001b[A\n",
      "  4%|▍         | 511/12500 [00:01<00:43, 276.87it/s]\u001b[A\n",
      "  4%|▍         | 543/12500 [00:01<00:42, 279.02it/s]\u001b[A\n",
      "  5%|▍         | 573/12500 [00:02<00:42, 279.87it/s]\u001b[A\n",
      "  5%|▍         | 603/12500 [00:02<00:42, 279.65it/s]\u001b[A\n",
      "  5%|▌         | 632/12500 [00:02<00:42, 279.01it/s]\u001b[A\n",
      "  5%|▌         | 661/12500 [00:02<00:42, 279.42it/s]\u001b[A\n",
      "  6%|▌         | 690/12500 [00:02<00:42, 279.81it/s]\u001b[A\n",
      "  6%|▌         | 719/12500 [00:02<00:42, 279.77it/s]\u001b[A\n",
      "  6%|▌         | 748/12500 [00:02<00:41, 280.13it/s]\u001b[A\n",
      "  6%|▌         | 777/12500 [00:02<00:41, 280.26it/s]\u001b[A\n",
      "  6%|▋         | 806/12500 [00:02<00:41, 280.24it/s]\u001b[A\n",
      "  7%|▋         | 835/12500 [00:02<00:41, 279.88it/s]\u001b[A\n",
      "  7%|▋         | 866/12500 [00:03<00:41, 280.51it/s]\u001b[A\n",
      "  7%|▋         | 895/12500 [00:03<00:41, 280.71it/s]\u001b[A\n",
      "  7%|▋         | 925/12500 [00:03<00:41, 280.98it/s]\u001b[A\n",
      "  8%|▊         | 956/12500 [00:03<00:40, 281.80it/s]\u001b[A\n",
      "  8%|▊         | 986/12500 [00:03<00:40, 282.03it/s]\u001b[A\n",
      "  8%|▊         | 1016/12500 [00:03<00:40, 282.11it/s]\u001b[A\n",
      "  8%|▊         | 1046/12500 [00:03<00:40, 281.91it/s]\u001b[A\n",
      "  9%|▊         | 1075/12500 [00:03<00:40, 281.97it/s]\u001b[A\n",
      "  9%|▉         | 1105/12500 [00:03<00:40, 282.26it/s]\u001b[A\n",
      "  9%|▉         | 1138/12500 [00:04<00:40, 283.29it/s]\u001b[A\n",
      "  9%|▉         | 1168/12500 [00:04<00:40, 283.18it/s]\u001b[A\n",
      " 10%|▉         | 1200/12500 [00:04<00:39, 283.96it/s]\u001b[A\n",
      " 10%|▉         | 1230/12500 [00:04<00:39, 283.60it/s]\u001b[A\n",
      " 10%|█         | 1260/12500 [00:04<00:39, 283.63it/s]\u001b[A\n",
      " 10%|█         | 1293/12500 [00:04<00:39, 284.59it/s]\u001b[A\n",
      " 11%|█         | 1324/12500 [00:04<00:39, 284.56it/s]\u001b[A\n",
      " 11%|█         | 1355/12500 [00:04<00:39, 284.84it/s]\u001b[A\n",
      " 11%|█         | 1386/12500 [00:04<00:38, 285.22it/s]\u001b[A\n",
      " 11%|█▏        | 1418/12500 [00:04<00:38, 285.86it/s]\u001b[A\n",
      " 12%|█▏        | 1449/12500 [00:05<00:38, 286.06it/s]\u001b[A\n",
      " 12%|█▏        | 1480/12500 [00:05<00:38, 286.12it/s]\u001b[A\n",
      " 12%|█▏        | 1510/12500 [00:05<00:38, 286.06it/s]\u001b[A\n",
      " 12%|█▏        | 1540/12500 [00:05<00:38, 285.96it/s]\u001b[A\n",
      " 13%|█▎        | 1569/12500 [00:05<00:38, 285.90it/s]\u001b[A\n",
      " 13%|█▎        | 1601/12500 [00:05<00:38, 286.31it/s]\u001b[A\n",
      " 13%|█▎        | 1634/12500 [00:05<00:37, 287.06it/s]\u001b[A\n",
      " 13%|█▎        | 1665/12500 [00:05<00:37, 287.03it/s]\u001b[A\n",
      " 14%|█▎        | 1695/12500 [00:05<00:37, 286.80it/s]\u001b[A\n",
      " 14%|█▍        | 1725/12500 [00:06<00:37, 287.01it/s]\u001b[A\n",
      " 14%|█▍        | 1756/12500 [00:06<00:37, 287.29it/s]\u001b[A\n",
      " 14%|█▍        | 1786/12500 [00:06<00:37, 287.38it/s]\u001b[A\n",
      " 15%|█▍        | 1816/12500 [00:06<00:37, 287.44it/s]\u001b[A\n",
      " 15%|█▍        | 1849/12500 [00:06<00:36, 288.06it/s]\u001b[A\n",
      "100%|██████████| 12500/12500 [00:40<00:00, 311.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# 处理，加载测试集数据\n",
    "test_data = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24965, 299, 299, 3) (24965,) (12500, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, train_targ.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆分验证集\n",
    "对标记数据进行处理，拆分验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_data, train_targ, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型InceptionV3\n",
    "预训练模型InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 has 315 layers.\n"
     ]
    }
   ],
   "source": [
    "# 构建InceptionV3\n",
    "def buid_inceptionv3():\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    input_tensor = keras.Input(shape=(299, 299, 3)) \n",
    "    input_tensor = keras.layers.Lambda(keras.applications.inception_v3.preprocess_input)(input_tensor)\n",
    "    base_model   = keras.applications.inception_v3.InceptionV3(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 锁定模型，保护处理\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 空域信号施加全局平均池化，dropout处理防止过拟合，重建全连接层\n",
    "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    result = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    result.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    print('InceptionV3 has %d layers.' % len(result.layers))\n",
    "    return result\n",
    "\n",
    "# 创建\n",
    "inceptionv3_obj = buid_inceptionv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "#keras.utils.plot_model(inceptionv3_obj, to_file='model_inceptionv3.png')\n",
    "#from IPython.display import SVG\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#SVG(model_to_dot(inceptionv3_obj).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19972 samples, validate on 4993 samples\n",
      "Epoch 1/10\n",
      "19972/19972 [==============================] - 291s 15ms/step - loss: 0.1987 - acc: 0.9325 - val_loss: 0.1156 - val_acc: 0.9579\n",
      "Epoch 2/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.1103 - acc: 0.9620 - val_loss: 0.0936 - val_acc: 0.9674\n",
      "Epoch 3/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.0934 - acc: 0.9650 - val_loss: 0.1784 - val_acc: 0.9345\n",
      "Epoch 4/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.0855 - acc: 0.9676 - val_loss: 0.0593 - val_acc: 0.9828\n",
      "Epoch 5/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.0857 - acc: 0.9674 - val_loss: 0.1073 - val_acc: 0.9650\n",
      "Epoch 6/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.0819 - acc: 0.9692 - val_loss: 0.0836 - val_acc: 0.9740\n",
      "Epoch 7/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.0852 - acc: 0.9675 - val_loss: 0.0464 - val_acc: 0.9876\n",
      "Epoch 8/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.0853 - acc: 0.9675 - val_loss: 0.0456 - val_acc: 0.9878\n",
      "Epoch 9/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.0817 - acc: 0.9696 - val_loss: 0.1249 - val_acc: 0.9581\n",
      "Epoch 10/10\n",
      "19972/19972 [==============================] - 285s 14ms/step - loss: 0.0820 - acc: 0.9705 - val_loss: 0.0587 - val_acc: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf60916710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "inceptionv3_obj.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "inceptionv3_predict = inceptionv3_obj.predict(test_data)\n",
    "inceptionv3_predict = inceptionv3_predict.clip(min=0.005, max=0.995)\n",
    "inceptionv3_predict = inceptionv3_predict.flatten(order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.989967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.993490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.994134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     label\n",
       "0    1  0.995000\n",
       "1    2  0.995000\n",
       "2    3  0.995000\n",
       "3    4  0.989967\n",
       "4    5  0.005000\n",
       "5    6  0.005000\n",
       "6    7  0.005000\n",
       "7    8  0.005000\n",
       "8    9  0.005000\n",
       "9   10  0.005000\n",
       "10  11  0.005000\n",
       "11  12  0.993490\n",
       "12  13  0.005000\n",
       "13  14  0.005000\n",
       "14  15  0.005000\n",
       "15  16  0.005000\n",
       "16  17  0.994134\n",
       "17  18  0.995000\n",
       "18  19  0.005000\n",
       "19  20  0.005000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': inceptionv3_predict})\n",
    "submission.to_csv('submission_inceptionv3.csv',index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型Xception\n",
    "预训练模型Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception has 136 layers.\n"
     ]
    }
   ],
   "source": [
    "# 构建xception\n",
    "def buid_xception():\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    input_tensor = keras.Input(shape=(299, 299, 3)) \n",
    "    input_tensor = keras.layers.Lambda(keras.applications.xception.preprocess_input)(input_tensor)\n",
    "    base_model   = keras.applications.xception.Xception(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 锁定模型，保护处理\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 空域信号施加全局平均池化，dropout处理防止过拟合，重建全连接层\n",
    "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    result = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    result.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    print('xception has %d layers.' % len(result.layers))\n",
    "    return result\n",
    "\n",
    "# 创建模型\n",
    "xception_obj = buid_xception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "#keras.utils.plot_model(xception_obj, to_file='model_xception.png')\n",
    "#SVG(model_to_dot(xception_obj).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19972 samples, validate on 4993 samples\n",
      "Epoch 1/10\n",
      "19972/19972 [==============================] - 497s 25ms/step - loss: 0.1420 - acc: 0.9666 - val_loss: 0.1090 - val_acc: 0.9686\n",
      "Epoch 2/10\n",
      "19972/19972 [==============================] - 493s 25ms/step - loss: 0.0615 - acc: 0.9814 - val_loss: 0.0602 - val_acc: 0.9846\n",
      "Epoch 3/10\n",
      "19972/19972 [==============================] - 494s 25ms/step - loss: 0.0513 - acc: 0.9833 - val_loss: 0.0524 - val_acc: 0.9862\n",
      "Epoch 4/10\n",
      "19972/19972 [==============================] - 491s 25ms/step - loss: 0.0489 - acc: 0.9835 - val_loss: 0.0874 - val_acc: 0.9720\n",
      "Epoch 5/10\n",
      "19972/19972 [==============================] - 489s 25ms/step - loss: 0.0457 - acc: 0.9853 - val_loss: 0.0676 - val_acc: 0.9798\n",
      "Epoch 6/10\n",
      "19972/19972 [==============================] - 489s 25ms/step - loss: 0.0436 - acc: 0.9855 - val_loss: 0.0419 - val_acc: 0.9892\n",
      "Epoch 7/10\n",
      "19972/19972 [==============================] - 489s 24ms/step - loss: 0.0436 - acc: 0.9854 - val_loss: 0.0641 - val_acc: 0.9818\n",
      "Epoch 8/10\n",
      "19972/19972 [==============================] - 489s 24ms/step - loss: 0.0420 - acc: 0.9848 - val_loss: 0.0522 - val_acc: 0.9862\n",
      "Epoch 9/10\n",
      "19972/19972 [==============================] - 489s 24ms/step - loss: 0.0396 - acc: 0.9861 - val_loss: 0.0640 - val_acc: 0.9828\n",
      "Epoch 10/10\n",
      "19972/19972 [==============================] - 488s 24ms/step - loss: 0.0411 - acc: 0.9853 - val_loss: 0.0702 - val_acc: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf15184240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "xception_obj.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "xception_predict = xception_obj.predict(test_data)\n",
    "xception_predict = xception_predict.clip(min=0.005, max=0.995)\n",
    "xception_predict = xception_predict.flatten(order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.987186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.985763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.976971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.862563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.779264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     label\n",
       "0    1  0.987186\n",
       "1    2  0.995000\n",
       "2    3  0.985763\n",
       "3    4  0.976971\n",
       "4    5  0.005000\n",
       "5    6  0.005000\n",
       "6    7  0.005000\n",
       "7    8  0.005000\n",
       "8    9  0.005000\n",
       "9   10  0.005000\n",
       "10  11  0.005000\n",
       "11  12  0.862563\n",
       "12  13  0.005000\n",
       "13  14  0.005000\n",
       "14  15  0.005000\n",
       "15  16  0.005000\n",
       "16  17  0.779264\n",
       "17  18  0.995000\n",
       "18  19  0.005000\n",
       "19  20  0.005000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': xception_predict})\n",
    "submission.to_csv('submission_xception.csv',index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型Inception ResnetV2\n",
    "预训练模型Inception ResnetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception ResnetV2 has 784 layers.\n"
     ]
    }
   ],
   "source": [
    "# 构建Inception ResnetV2\n",
    "def buid_inception_resnet_v2():\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    input_tensor = keras.Input(shape=(299, 299, 3)) \n",
    "    input_tensor = keras.layers.Lambda(keras.applications.inception_resnet_v2.preprocess_input)(input_tensor)\n",
    "    base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 锁定模型，保护处理\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 空域信号施加全局平均池化，dropout处理防止过拟合，重建全连接层\n",
    "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    result = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    result.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    print('Inception ResnetV2 has %d layers.' % len(result.layers))\n",
    "    return result\n",
    "\n",
    "# 创建\n",
    "inception_resnet_v2_obj = buid_inception_resnet_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "#keras.utils.plot_model(inception_resnet_v2_obj, to_file='model_inception_resnet_v2.png')\n",
    "#SVG(model_to_dot(inception_resnet_v2_obj).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19972 samples, validate on 4993 samples\n",
      "Epoch 1/10\n",
      "19972/19972 [==============================] - 648s 32ms/step - loss: 0.1846 - acc: 0.9438 - val_loss: 0.0557 - val_acc: 0.9858\n",
      "Epoch 2/10\n",
      "19972/19972 [==============================] - 636s 32ms/step - loss: 0.0880 - acc: 0.9708 - val_loss: 0.0773 - val_acc: 0.9748\n",
      "Epoch 3/10\n",
      "19972/19972 [==============================] - 636s 32ms/step - loss: 0.0773 - acc: 0.9726 - val_loss: 0.0523 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "19972/19972 [==============================] - 636s 32ms/step - loss: 0.0716 - acc: 0.9741 - val_loss: 0.0391 - val_acc: 0.9886\n",
      "Epoch 5/10\n",
      "19972/19972 [==============================] - 636s 32ms/step - loss: 0.0700 - acc: 0.9739 - val_loss: 0.1020 - val_acc: 0.9648\n",
      "Epoch 6/10\n",
      "19972/19972 [==============================] - 638s 32ms/step - loss: 0.0651 - acc: 0.9772 - val_loss: 0.0279 - val_acc: 0.9940\n",
      "Epoch 7/10\n",
      "19972/19972 [==============================] - 637s 32ms/step - loss: 0.0661 - acc: 0.9757 - val_loss: 0.0641 - val_acc: 0.9806\n",
      "Epoch 8/10\n",
      "19972/19972 [==============================] - 637s 32ms/step - loss: 0.0624 - acc: 0.9770 - val_loss: 0.0695 - val_acc: 0.9786\n",
      "Epoch 9/10\n",
      "19972/19972 [==============================] - 638s 32ms/step - loss: 0.0634 - acc: 0.9763 - val_loss: 0.0577 - val_acc: 0.9822\n",
      "Epoch 10/10\n",
      "19972/19972 [==============================] - 638s 32ms/step - loss: 0.0628 - acc: 0.9767 - val_loss: 0.0400 - val_acc: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbee0527438>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "inception_resnet_v2_obj.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "inception_resnet_v2_predict = inception_resnet_v2_obj.predict(test_data)\n",
    "inception_resnet_v2_predict = inception_resnet_v2_predict.clip(min=0.005, max=0.995)\n",
    "inception_resnet_v2_predict = inception_resnet_v2_predict.flatten(order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.913804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.993648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     label\n",
       "0    1  0.995000\n",
       "1    2  0.995000\n",
       "2    3  0.995000\n",
       "3    4  0.995000\n",
       "4    5  0.005000\n",
       "5    6  0.005000\n",
       "6    7  0.005000\n",
       "7    8  0.005000\n",
       "8    9  0.005000\n",
       "9   10  0.005000\n",
       "10  11  0.005000\n",
       "11  12  0.913804\n",
       "12  13  0.005000\n",
       "13  14  0.005000\n",
       "14  15  0.005000\n",
       "15  16  0.005000\n",
       "16  17  0.993648\n",
       "17  18  0.995000\n",
       "18  19  0.005000\n",
       "19  20  0.005000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': inception_resnet_v2_predict})\n",
    "submission.to_csv('submission_inception_resnet_v2.csv',index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征，融合模型\n",
    "将多个模型到特征向量融合训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# 提取模型的特征数据（原版本）\n",
    "def pick_features(raw_model, pre_input):\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    inputs       = keras.Input(shape=(299, 299, 3))\n",
    "    input_tensor = keras.layers.Lambda(pre_input)(inputs)\n",
    "    base_model   = raw_model(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 提取特征数据\n",
    "    x     = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    model = keras.models.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    train_feature = model.predict(x_train, batch_size=64)\n",
    "    test_feature  = model.predict(test_data, batch_size=64)\n",
    "\n",
    "    # 返回\n",
    "    with h5py.File(\"feature_%s.h5\" % raw_model.__name__, 'w') as f:\n",
    "        f.create_dataset('train', data=train_feature)\n",
    "        f.create_dataset('test',  data=test_feature)\n",
    "        f.create_dataset('label', data=y_train)\n",
    "    #return train_feature, test_feature\n",
    "    \n",
    "    \n",
    "# # 提取模型的特征数据（调整后）\n",
    "# def pick_features(raw_model, pre_input, image_size=(299, 299)):\n",
    "\n",
    "#     # 获取基础模型，不保留顶层的全连接网络\n",
    "#     inputs       = keras.Input(shape=(image_size[0], image_size[1], 3))\n",
    "#     input_tensor = inputs\n",
    "#     if pre_input:\n",
    "#         input_tensor = keras.layers.Lambda(pre_input)(inputs)\n",
    "#     base_model   = raw_model(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "#     # 提取特征数据\n",
    "#     x     = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "#     model = keras.models.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "#     gen = keras.preprocessing.image.ImageDataGenerator()\n",
    "#     train_generator = gen.flow_from_directory(\"data/gen_train\", image_size, shuffle=False, batch_size=16)\n",
    "#     test_generator = gen.flow_from_directory(\"data/gen_test\", image_size, shuffle=False, batch_size=16, class_mode=None)\n",
    "#     train_feature = model.predict_generator(train_generator)\n",
    "#     test_feature = model.predict_generator(test_generator) \n",
    "    \n",
    "    \n",
    "#     # 返回\n",
    "#     with h5py.File(\"feature_%s.h5\" % raw_model.__name__, 'w') as f:\n",
    "#         f.create_dataset('train', data=train_feature)\n",
    "#         f.create_dataset('test',  data=test_feature)\n",
    "#         f.create_dataset('label', data=train_generator.classes)\n",
    "#     #return train_feature, test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取inceptionv3特征数据\n",
    "pick_features(keras.applications.inception_v3.InceptionV3, keras.applications.inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取xception特征数据\n",
    "pick_features(keras.applications.xception.Xception, keras.applications.xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取inception_resnet_v2特征数据\n",
    "pick_features(keras.applications.inception_resnet_v2.InceptionResNetV2, keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取ResNet50特征数据\n",
    "#pick_features(keras.applications.resnet50.ResNet50, None, (244,244))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "构建最终的模型，用特征数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test= [], []\n",
    "label = None\n",
    "for fetchfile in ['feature_Xception.h5', 'feature_InceptionV3.h5', 'feature_InceptionResNetV2.h5']:\n",
    "    with h5py.File(fetchfile, 'r') as h:\n",
    "        train.append(np.array(h['train']))\n",
    "        test.append(np.array(h['test']))\n",
    "        label = np.array(h['label'])\n",
    "        \n",
    "train_data_feature = np.concatenate(train, axis=1)\n",
    "test_data_feature  = np.concatenate(test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 随机处理\n",
    "train_data_feature, label = shuffle(train_data_feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ft_train, x_ft_valid, y_ft_train, y_ft_valid = train_test_split(train_data_feature, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建融合模型\n",
    "def buid_final_model():\n",
    "\n",
    "    inputs = keras.Input(shape=(x_ft_train.shape[1],))\n",
    "    x = keras.layers.Dropout(0.4)(inputs)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    final_model = keras.models.Model(inputs=inputs, outputs=x)\n",
    "    final_model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    return final_model\n",
    "\n",
    "\n",
    "# 最终模型\n",
    "final_model_obj = buid_final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化展示\n",
    "展示构建的最终模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "#keras.utils.plot_model(final_model_obj, to_file='model.png')\n",
    "\n",
    "#from IPython.display import SVG\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#SVG(model_to_dot(final_model_obj).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 训练最终模型\n",
    "def train_final_model(final_model):\n",
    "\n",
    "    # 模型保存位置\n",
    "    logs_file = 'ft_extract_features-{val_loss:.4f}.h5'\n",
    "    path = os.getcwd()\n",
    "    path_logs = os.path.join(path, logs_file)\n",
    "\n",
    "    #early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    #model_check = keras.callbacks.ModelCheckpoint(path_logs, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    #final_model.fit(x_ft_train, y_ft_train, batch_size=64, epochs=10, \n",
    "    #           validation_data=(x_ft_valid, y_ft_valid), callbacks=[early_stop, model_check])\n",
    "    final_model.fit(train_data_feature, label, batch_size=64, nb_epoch=10, validation_split=0.2)\n",
    "    final_model.save(path_logs)\n",
    "    \n",
    "\n",
    "# 训练\n",
    "train_final_model(final_model_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "final_predict = final_model_obj.predict(test_data_feature)\n",
    "final_predict = final_predict.clip(min=0.005, max=0.995)\n",
    "final_predict = final_predict.flatten(order = 'F')\n",
    "\n",
    "#print(final_predict)\n",
    "#print(test_data_feature)\n",
    "\n",
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': final_predict})\n",
    "submission.to_csv('submission_final.csv',index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数损失曲线\n",
    "绘制模型的对数损失曲线，直观展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 对数损失更新曲线\n",
    "def show_loss(final_model):\n",
    "    fig, ax = plt.subplots(2,1)\n",
    "    his_model = final_model.history\n",
    "    history = his_model.history\n",
    "    ax[0].plot(history['loss'], color='b', label=\"loss\")\n",
    "    ax[0].plot(history['val_loss'], color='r', label=\"val_loss\",axes =ax[0])\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "    ax[1].plot(history['acc'], color='g', label=\"acc\")\n",
    "    ax[1].plot(history['val_acc'], color='c',label=\"val_acc\")\n",
    "    legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "# 绘制\n",
    "show_loss(final_model_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
