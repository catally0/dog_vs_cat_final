{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测python版本\n",
    "这里我们使用的python的版本为3.6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "为了更好的训练模型，这里对数据进行一定程度对预处理\n",
    "- 删除训练数据集中过大（`500*500`以上）和过小（`100*100`以下）的图片。\n",
    "- 将图片按照一定的目录结构归类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from PIL import Image\n",
    "\n",
    "# 删除不合尺寸\n",
    "def pick_bad_pics(path, bad_path):\n",
    "    bad_list = []\n",
    "    img_list = os.listdir(path)\n",
    "    for img_name in img_list:\n",
    "        im_path = os.path.join(path, img_name)\n",
    "        im = Image.open(im_path)\n",
    "        w, h = im.size\n",
    "        if w > 500 or h > 500 or w < 100 or h < 100:\n",
    "            bad_list.append(img_name)\n",
    "            shutil.move(im_path, os.path.join(bad_path, img_name))\n",
    "    print(len(bad_list))\n",
    "    # return bad_list\n",
    "\n",
    "pick_bad_pics(\"data/train\", \"data/train_bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取加载数据集，归一化处理\n",
    "将用于训练的数据集加载到内存，等待处理。主要是转化为ndarray类型到数据，方便后续到计算和处理.因为选择到预训练模型，对于图片到要求都是`299*299`大小，这里我们读取数据时，图片统一调整到这个尺寸。\n",
    "- 加载训练集数据。\n",
    "- 加载测试集数据。\n",
    "- 输出一个经过正规化的、Numpy array 格式的图像数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 加载训练集\n",
    "def load_train_data():\n",
    "\n",
    "    cat = glob.glob(\"data/train/cat.*.jpg\")\n",
    "    dog = glob.glob(\"data/train/dog.*.jpg\")\n",
    "    train_data = np.zeros(((len(cat)+len(dog)), 299, 299, 3), dtype=np.uint8)\n",
    "    train_targ = np.array([0]*len(cat) + [1]*len(dog))\n",
    "\n",
    "    i = 0\n",
    "    for img_name in tqdm(cat):\n",
    "        img = cv2.imread(img_name)\n",
    "        train_data[i] = cv2.resize(img,(299, 299))\n",
    "        i += 1\n",
    "    for img_name in tqdm(dog):\n",
    "        img = cv2.imread(img_name)\n",
    "        train_data[i] = cv2.resize(img,(299, 299))\n",
    "        i += 1\n",
    "\n",
    "    return train_data, train_targ\n",
    "\n",
    "# 加载测试集\n",
    "def load_test_data():\n",
    "\n",
    "    test = glob.glob(\"data/test/*.jpg\")\n",
    "    test_data = np.zeros((len(test), 299, 299, 3), dtype=np.uint8)\n",
    "    \n",
    "    i = 0\n",
    "    for img_name in tqdm(test):\n",
    "        img = cv2.imread(img_name)\n",
    "        test_data[i] = cv2.resize(img,(299, 299))\n",
    "        i += 1\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12400/12400 [00:39<00:00, 317.91it/s]\n",
      "100%|██████████| 12395/12395 [00:40<00:00, 308.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# 处理，加载训练集数据\n",
    "train_data, train_targ = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:39<00:00, 313.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# 处理，加载测试集数据\n",
    "test_data = load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆分验证集\n",
    "对标记数据进行处理，拆分验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_data, train_targ, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型InceptionV3\n",
    "预训练模型InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 has 315 layers.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "# 构建InceptionV3\n",
    "def buid_inceptionv3():\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    input_tensor = keras.Input(shape=(299, 299, 3)) \n",
    "    input_tensor = keras.layers.Lambda(keras.applications.inception_v3.preprocess_input)(input_tensor)\n",
    "    base_model   = keras.applications.inception_v3.InceptionV3(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 锁定模型，保护处理\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 空域信号施加全局平均池化，dropout处理防止过拟合，重建全连接层\n",
    "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    result = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    result.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    print('InceptionV3 has %d layers.' % len(result.layers))\n",
    "    return result\n",
    "\n",
    "# 创建\n",
    "inceptionv3_obj = buid_inceptionv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "keras.utils.plot_model(inceptionv3_obj, to_file='model_inceptionv3.png')\n",
    "#from IPython.display import SVG\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#SVG(model_to_dot(inceptionv3_obj).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19836 samples, validate on 4959 samples\n",
      "Epoch 1/10\n",
      "19836/19836 [==============================] - 299s 15ms/step - loss: 0.1726 - acc: 0.9391 - val_loss: 0.0936 - val_acc: 0.9704\n",
      "Epoch 2/10\n",
      "19836/19836 [==============================] - 292s 15ms/step - loss: 0.0993 - acc: 0.9636 - val_loss: 0.0917 - val_acc: 0.9702\n",
      "Epoch 3/10\n",
      "19836/19836 [==============================] - 292s 15ms/step - loss: 0.0933 - acc: 0.9641 - val_loss: 0.1101 - val_acc: 0.9641\n",
      "Epoch 4/10\n",
      "19836/19836 [==============================] - 292s 15ms/step - loss: 0.0893 - acc: 0.9661 - val_loss: 0.0569 - val_acc: 0.9810\n",
      "Epoch 5/10\n",
      "19836/19836 [==============================] - 292s 15ms/step - loss: 0.0848 - acc: 0.9685 - val_loss: 0.0703 - val_acc: 0.9774\n",
      "Epoch 6/10\n",
      "19836/19836 [==============================] - 292s 15ms/step - loss: 0.0839 - acc: 0.9684 - val_loss: 0.0991 - val_acc: 0.9679\n",
      "Epoch 7/10\n",
      "19836/19836 [==============================] - 292s 15ms/step - loss: 0.0846 - acc: 0.9686 - val_loss: 0.0671 - val_acc: 0.9780\n",
      "Epoch 8/10\n",
      "19836/19836 [==============================] - 292s 15ms/step - loss: 0.0814 - acc: 0.9688 - val_loss: 0.1188 - val_acc: 0.9625\n",
      "Epoch 9/10\n",
      "19836/19836 [==============================] - 291s 15ms/step - loss: 0.0802 - acc: 0.9697 - val_loss: 0.1396 - val_acc: 0.9550\n",
      "Epoch 10/10\n",
      "19836/19836 [==============================] - 292s 15ms/step - loss: 0.0837 - acc: 0.9697 - val_loss: 0.1015 - val_acc: 0.9675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7df1ad6390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "inceptionv3_obj.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "inceptionv3_predict = inceptionv3_obj.predict(test_data)\n",
    "inceptionv3_predict = inceptionv3_predict.clip(min=0.005, max=0.995)\n",
    "inceptionv3_predict = inceptionv3_predict.flatten(order = 'F')\n",
    "\n",
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': inceptionv3_predict})\n",
    "submission.to_csv('inceptionv3_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型Xception\n",
    "预训练模型Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception has 136 layers.\n"
     ]
    }
   ],
   "source": [
    "# 构建xception\n",
    "def buid_xception():\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    input_tensor = keras.Input(shape=(299, 299, 3)) \n",
    "    input_tensor = keras.layers.Lambda(keras.applications.xception.preprocess_input)(input_tensor)\n",
    "    base_model   = keras.applications.xception.Xception(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 锁定模型，保护处理\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 空域信号施加全局平均池化，dropout处理防止过拟合，重建全连接层\n",
    "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    result = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    result.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    print('xception has %d layers.' % len(result.layers))\n",
    "    return result\n",
    "\n",
    "# 创建模型\n",
    "xception_obj = buid_xception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "keras.utils.plot_model(xception_obj, to_file='model_xception.png')\n",
    "#SVG(model_to_dot(xception_obj).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19836 samples, validate on 4959 samples\n",
      "Epoch 1/10\n",
      "19836/19836 [==============================] - 505s 25ms/step - loss: 0.1170 - acc: 0.9693 - val_loss: 0.0943 - val_acc: 0.9716\n",
      "Epoch 2/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0543 - acc: 0.9822 - val_loss: 0.0626 - val_acc: 0.9806\n",
      "Epoch 3/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0491 - acc: 0.9829 - val_loss: 0.0752 - val_acc: 0.9760\n",
      "Epoch 4/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0478 - acc: 0.9832 - val_loss: 0.0569 - val_acc: 0.9819\n",
      "Epoch 5/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0470 - acc: 0.9834 - val_loss: 0.0470 - val_acc: 0.9865\n",
      "Epoch 6/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0468 - acc: 0.9835 - val_loss: 0.0814 - val_acc: 0.9752\n",
      "Epoch 7/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0458 - acc: 0.9840 - val_loss: 0.0560 - val_acc: 0.9827\n",
      "Epoch 8/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0428 - acc: 0.9852 - val_loss: 0.0820 - val_acc: 0.9750\n",
      "Epoch 9/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0419 - acc: 0.9854 - val_loss: 0.0591 - val_acc: 0.9810\n",
      "Epoch 10/10\n",
      "19836/19836 [==============================] - 500s 25ms/step - loss: 0.0392 - acc: 0.9862 - val_loss: 0.0867 - val_acc: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7df1aa0fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "xception_obj.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "xception_predict = xception_obj.predict(test_data)\n",
    "xception_predict = xception_predict.clip(min=0.005, max=0.995)\n",
    "xception_predict = xception_predict.flatten(order = 'F')\n",
    "\n",
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': xception_predict})\n",
    "submission.to_csv('xception_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型Inception ResnetV2\n",
    "预训练模型Inception ResnetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception ResnetV2 has 784 layers.\n"
     ]
    }
   ],
   "source": [
    "# 构建Inception ResnetV2\n",
    "def buid_inception_resnet_v2():\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    input_tensor = keras.Input(shape=(299, 299, 3)) \n",
    "    input_tensor = keras.layers.Lambda(keras.applications.inception_resnet_v2.preprocess_input)(input_tensor)\n",
    "    base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 锁定模型，保护处理\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 空域信号施加全局平均池化，dropout处理防止过拟合，重建全连接层\n",
    "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = keras.layers.Dropout(0.25)(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    result = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    result.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    print('Inception ResnetV2 has %d layers.' % len(result.layers))\n",
    "    return result\n",
    "\n",
    "# 创建\n",
    "inception_resnet_v2_obj = buid_inception_resnet_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型\n",
    "#keras.utils.plot_model(inception_resnet_v2_obj, to_file='model_inception_resnet_v2.png')\n",
    "#SVG(model_to_dot(inception_resnet_v2_obj).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19836 samples, validate on 4959 samples\n",
      "Epoch 1/10\n",
      "19836/19836 [==============================] - 683s 34ms/step - loss: 0.1395 - acc: 0.9577 - val_loss: 0.0809 - val_acc: 0.9730\n",
      "Epoch 2/10\n",
      "19836/19836 [==============================] - 671s 34ms/step - loss: 0.0805 - acc: 0.9711 - val_loss: 0.0733 - val_acc: 0.9738\n",
      "Epoch 3/10\n",
      "19836/19836 [==============================] - 671s 34ms/step - loss: 0.0722 - acc: 0.9747 - val_loss: 0.0586 - val_acc: 0.9786\n",
      "Epoch 4/10\n",
      "19836/19836 [==============================] - 671s 34ms/step - loss: 0.0726 - acc: 0.9730 - val_loss: 0.0528 - val_acc: 0.9806\n",
      "Epoch 5/10\n",
      "19836/19836 [==============================] - 670s 34ms/step - loss: 0.0656 - acc: 0.9778 - val_loss: 0.0786 - val_acc: 0.9708\n",
      "Epoch 6/10\n",
      "19836/19836 [==============================] - 668s 34ms/step - loss: 0.0656 - acc: 0.9766 - val_loss: 0.0753 - val_acc: 0.9724\n",
      "Epoch 7/10\n",
      "19836/19836 [==============================] - 668s 34ms/step - loss: 0.0634 - acc: 0.9762 - val_loss: 0.0426 - val_acc: 0.9849\n",
      "Epoch 8/10\n",
      "19836/19836 [==============================] - 668s 34ms/step - loss: 0.0636 - acc: 0.9760 - val_loss: 0.0606 - val_acc: 0.9788\n",
      "Epoch 9/10\n",
      "19836/19836 [==============================] - 668s 34ms/step - loss: 0.0607 - acc: 0.9781 - val_loss: 0.0781 - val_acc: 0.9718\n",
      "Epoch 10/10\n",
      "19836/19836 [==============================] - 668s 34ms/step - loss: 0.0607 - acc: 0.9778 - val_loss: 0.0634 - val_acc: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7dc08543c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "inception_resnet_v2_obj.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "inception_resnet_v2_predict = inception_resnet_v2_obj.predict(test_data)\n",
    "inception_resnet_v2_predict = inception_resnet_v2_predict.clip(min=0.005, max=0.995)\n",
    "inception_resnet_v2_predict = inception_resnet_v2_predict.flatten(order = 'F')\n",
    "\n",
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': inception_resnet_v2_predict})\n",
    "submission.to_csv('inception_resnet_v2_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取特征，融合模型\n",
    "将多个模型到特征向量融合训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# 提取模型的特征数据\n",
    "def pick_features(raw_model, pre_input):\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    inputs       = keras.Input(shape=(299, 299, 3))\n",
    "    input_tensor = keras.layers.Lambda(pre_input)(inputs)\n",
    "    base_model   = raw_model(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 提取特征数据\n",
    "    x     = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    model = keras.models.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    train_feature = model.predict(x_train, batch_size=64)\n",
    "    test_feature  = model.predict(test_data, batch_size=64)\n",
    "\n",
    "    # 返回\n",
    "    with h5py.File(\"feature_%s.h5\" % raw_model.__name__, 'w') as f:\n",
    "        f.create_dataset('train', data=train_feature)\n",
    "        f.create_dataset('test',  data=test_feature)\n",
    "        f.create_dataset('label', data=y_train)\n",
    "    return train_feature, test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取inceptionv3特征数据\n",
    "train_inceptionv3, test_inceptionv3 = pick_features(keras.applications.inception_v3.InceptionV3\n",
    "                                                    , keras.applications.inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取xception特征数据\n",
    "train_xception, test_xception = pick_features(keras.applications.xception.Xception\n",
    "                                              , keras.applications.xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取inception_resnet_v2特征数据\n",
    "train_inception_resnet_v2, test_inception_resnet_v2 = pick_features(\n",
    "    keras.applications.inception_resnet_v2.InceptionResNetV2, keras.applications.inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "构建最终的模型，用特征数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test= [], []\n",
    "for fetchfile in ['feature_Xception.h5', 'feature_InceptionV3.h5', 'feature_InceptionResNetV2.h5']:\n",
    "    with h5py.File(fetchfile, 'r') as h:\n",
    "        train.append(np.array(h['train']))\n",
    "        test.append(np.array(h['test']))\n",
    "        label = np.array(h['label'])\n",
    "        \n",
    "train_data_feature = np.concatenate(train, axis=1)\n",
    "test_data_feature  = np.concatenate(test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ft_train, x_ft_valid, y_ft_train, y_ft_valid = train_test_split(train_data_feature, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建融合模型\n",
    "def buid_final_model():\n",
    "\n",
    "    inputs = keras.Input(shape=(x_ft_train.shape[1],))\n",
    "    x = keras.layers.Dropout(0.25)(inputs)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    final_model = keras.models.Model(inputs=inputs, outputs=x)\n",
    "    final_model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    return final_model\n",
    "\n",
    "\n",
    "# 最终模型\n",
    "final_model_obj = buid_final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化展示\n",
    "展示构建的最终模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 140.00 191.00\" width=\"140pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-187 136,-187 136,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140176604779016 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140176604779016</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 132,-182.5 132,-146.5 0,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-160.8\">input_15: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140176604425184 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140176604425184</title>\n",
       "<polygon fill=\"none\" points=\"3.5,-73.5 3.5,-109.5 128.5,-109.5 128.5,-73.5 3.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-87.8\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 140176604779016&#45;&gt;140176604425184 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140176604779016-&gt;140176604425184</title>\n",
       "<path d=\"M66,-146.4551C66,-138.3828 66,-128.6764 66,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"69.5001,-119.5903 66,-109.5904 62.5001,-119.5904 69.5001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140176604530504 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140176604530504</title>\n",
       "<polygon fill=\"none\" points=\"15,-.5 15,-36.5 117,-36.5 117,-.5 15,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-14.8\">dense_4: Dense</text>\n",
       "</g>\n",
       "<!-- 140176604425184&#45;&gt;140176604530504 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140176604425184-&gt;140176604530504</title>\n",
       "<path d=\"M66,-73.4551C66,-65.3828 66,-55.6764 66,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"69.5001,-46.5903 66,-36.5904 62.5001,-46.5904 69.5001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可视化模型\n",
    "keras.utils.plot_model(final_model_obj, to_file='model.png')\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(final_model_obj).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15868 samples, validate on 3968 samples\n",
      "Epoch 1/10\n",
      "15868/15868 [==============================] - 24s 2ms/step - loss: 0.0402 - acc: 0.9888 - val_loss: 0.0273 - val_acc: 0.9902\n",
      "Epoch 2/10\n",
      "15868/15868 [==============================] - 4s 280us/step - loss: 0.0162 - acc: 0.9953 - val_loss: 0.0186 - val_acc: 0.9942\n",
      "Epoch 3/10\n",
      "15868/15868 [==============================] - 4s 267us/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0212 - val_acc: 0.9934\n",
      "Epoch 4/10\n",
      "15868/15868 [==============================] - 4s 261us/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0181 - val_acc: 0.9947\n",
      "Epoch 5/10\n",
      "15868/15868 [==============================] - 3s 211us/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.0215 - val_acc: 0.9937\n",
      "Epoch 6/10\n",
      "15868/15868 [==============================] - 3s 220us/step - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0170 - val_acc: 0.9952\n",
      "Epoch 7/10\n",
      "15868/15868 [==============================] - 3s 210us/step - loss: 0.0095 - acc: 0.9975 - val_loss: 0.0185 - val_acc: 0.9947\n",
      "Epoch 8/10\n",
      "15868/15868 [==============================] - 3s 210us/step - loss: 0.0087 - acc: 0.9976 - val_loss: 0.0184 - val_acc: 0.9947\n",
      "Epoch 9/10\n",
      "15868/15868 [==============================] - 3s 209us/step - loss: 0.0091 - acc: 0.9976 - val_loss: 0.0197 - val_acc: 0.9937\n",
      "Epoch 10/10\n",
      "15868/15868 [==============================] - 3s 208us/step - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0183 - val_acc: 0.9947\n"
     ]
    }
   ],
   "source": [
    "# 训练最终模型\n",
    "def train_final_model(final_model):\n",
    "\n",
    "    # 模型保存位置\n",
    "    logs_file = 'ft_extract_features-{val_loss:.4f}.h5'\n",
    "    path = os.getcwd()\n",
    "    path_logs = os.path.join(path, logs_file)\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_check = keras.callbacks.ModelCheckpoint(path_logs, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    final_model.fit(x_ft_train, y_ft_train, batch_size=32, epochs=10, \n",
    "               validation_data=(x_ft_valid, y_ft_valid), callbacks=[early_stop, model_check])\n",
    "\n",
    "# 训练\n",
    "train_final_model(final_model_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "final_predict = final_model_obj.predict(test_data_feature)\n",
    "final_predict = final_predict.clip(min=0.005, max=0.995)\n",
    "final_predict = final_predict.flatten(order = 'F')\n",
    "\n",
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': final_predict})\n",
    "submission.to_csv('final_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数损失曲线\n",
    "绘制模型的对数损失曲线，直观展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 对数损失更新曲线\n",
    "def show_loss(final_model):\n",
    "    fig, ax = plt.subplots(2,1)\n",
    "    his_model = final_model.history\n",
    "    history = his_model.history\n",
    "    ax[0].plot(history['loss'], color='b', label=\"loss\")\n",
    "    ax[0].plot(history['val_loss'], color='r', label=\"val_loss\",axes =ax[0])\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "    ax[1].plot(history['acc'], color='g', label=\"acc\")\n",
    "    ax[1].plot(history['val_acc'], color='c',label=\"val_acc\")\n",
    "    legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "# 绘制\n",
    "show_loss(final_model_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
