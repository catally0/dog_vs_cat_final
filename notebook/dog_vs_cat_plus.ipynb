{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测python版本\n",
    "这里我们使用的python的版本为3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "为了更好的训练模型，这里对数据进行一定程度对预处理\n",
    "- 删除训练数据集中过大（`500*500`以上）和过小（`100*100`以下）的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from PIL import Image\n",
    "\n",
    "# 删除不合尺寸\n",
    "def pick_bad_pics(path, bad_path):\n",
    "\n",
    "    # 没有目录，补充创建\n",
    "    if not os.path.isdir(bad_path):\n",
    "        os.mkdir(bad_path)\n",
    "    \n",
    "    bad_list = []\n",
    "    img_list = os.listdir(path)\n",
    "    for img_name in img_list:\n",
    "        im_path = os.path.join(path, img_name)\n",
    "        im = Image.open(im_path)\n",
    "        w, h = im.size\n",
    "        if w > 500 or h > 500 or w < 10 or h < 10:\n",
    "            bad_list.append(img_name)\n",
    "            shutil.move(im_path, os.path.join(bad_path, img_name))\n",
    "    print(len(bad_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pick_bad_pics(\"data/train\", \"data/train_bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取加载数据集，归一化处理\n",
    "将用于训练的数据集加载到内存，等待处理。主要是转化为ndarray类型到数据，方便后续到计算和处理。\n",
    "- 加载训练集数据。\n",
    "- 加载测试集数据。\n",
    "- 输出一个经过正规化的、Numpy array 格式的图像数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 加载训练集\n",
    "def load_train_data(image_size):\n",
    "\n",
    "    cat = glob.glob(\"data/train/cat.*.jpg\")\n",
    "    dog = glob.glob(\"data/train/dog.*.jpg\")\n",
    "    train_data = np.zeros(((len(cat)+len(dog)), image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    train_targ = np.array([0]*len(cat) + [1]*len(dog))\n",
    "\n",
    "    i = 0\n",
    "    for img_name in tqdm(cat):\n",
    "        img = cv2.imread(img_name)\n",
    "        train_data[i] = cv2.resize(img,image_size)\n",
    "        i += 1\n",
    "    for img_name in tqdm(dog):\n",
    "        img = cv2.imread(img_name)\n",
    "        train_data[i] = cv2.resize(img,image_size)\n",
    "        i += 1\n",
    "\n",
    "    return train_data, train_targ\n",
    "\n",
    "# 加载测试集\n",
    "def load_test_data(image_size):\n",
    "\n",
    "    test = glob.glob(\"data/test/*.jpg\")\n",
    "    test_data = np.zeros((len(test), image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for img_name in tqdm(test):\n",
    "        index = int(img_name[img_name.rfind('/')+1:img_name.rfind('.')])\n",
    "        #print(\"index=%d name=%s\" % (index, img_name))\n",
    "        img = cv2.imread(img_name)\n",
    "        test_data[index-1] = cv2.resize(img,image_size)\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 244*244数据预处理\n",
    " - 用作ResNet50模型的筛选训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12499/12499 [00:37<00:00, 336.65it/s]\n",
      "100%|██████████| 12499/12499 [00:38<00:00, 326.85it/s]\n",
      "100%|██████████| 12500/12500 [00:38<00:00, 328.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24998, 244, 244, 3) (24998,) (12500, 244, 244, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 处理，加载训练集数据\n",
    "train_data, train_targ = load_train_data((244,244))\n",
    "\n",
    "# 处理，加载测试集数据\n",
    "test_data = load_test_data((244,244))\n",
    "\n",
    "# 展示\n",
    "print(train_data.shape, train_targ.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆分验证集\n",
    "对标记数据进行处理，拆分验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分数据\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_data, train_targ, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型ResNet50\n",
    "预训练模型ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50 has 179 layers.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "# 构建ResNet50\n",
    "def buid_resnet50():\n",
    "\n",
    "    # 获取基础模型，不保留顶层的全连接网络\n",
    "    input_tensor = keras.Input(shape=(244, 244, 3)) \n",
    "    input_tensor = keras.layers.Lambda(keras.applications.resnet50.preprocess_input)(input_tensor)\n",
    "    base_model   = keras.applications.resnet50.ResNet50(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    # 锁定模型，保护处理\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 空域信号施加全局平均池化，dropout处理防止过拟合，重建全连接层\n",
    "    x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # 配置模型\n",
    "    result = keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    result.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 返回\n",
    "    print('ResNet50 has %d layers.' % len(result.layers))\n",
    "    return result\n",
    "\n",
    "# 创建\n",
    "resnet50_obj = buid_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19998 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "19998/19998 [==============================] - 250s 13ms/step - loss: 0.1430 - acc: 0.9450 - val_loss: 0.0602 - val_acc: 0.9796\n",
      "Epoch 2/10\n",
      "19998/19998 [==============================] - 247s 12ms/step - loss: 0.0809 - acc: 0.9700 - val_loss: 0.0880 - val_acc: 0.9716\n",
      "Epoch 3/10\n",
      "19998/19998 [==============================] - 248s 12ms/step - loss: 0.0706 - acc: 0.9729 - val_loss: 0.0669 - val_acc: 0.9792\n",
      "Epoch 4/10\n",
      "19998/19998 [==============================] - 248s 12ms/step - loss: 0.0683 - acc: 0.9734 - val_loss: 0.0719 - val_acc: 0.9778\n",
      "Epoch 5/10\n",
      "19998/19998 [==============================] - 248s 12ms/step - loss: 0.0620 - acc: 0.9761 - val_loss: 0.0626 - val_acc: 0.9826\n",
      "Epoch 6/10\n",
      "19998/19998 [==============================] - 248s 12ms/step - loss: 0.0609 - acc: 0.9754 - val_loss: 0.0764 - val_acc: 0.9770\n",
      "Epoch 7/10\n",
      "19998/19998 [==============================] - 248s 12ms/step - loss: 0.0636 - acc: 0.9751 - val_loss: 0.1044 - val_acc: 0.9700\n",
      "Epoch 8/10\n",
      "19998/19998 [==============================] - 248s 12ms/step - loss: 0.0594 - acc: 0.9774 - val_loss: 0.0659 - val_acc: 0.9808\n",
      "Epoch 9/10\n",
      "19998/19998 [==============================] - 248s 12ms/step - loss: 0.0578 - acc: 0.9776 - val_loss: 0.0631 - val_acc: 0.9820\n",
      "Epoch 10/10\n",
      "14912/19998 [=====================>........] - ETA: 47s - loss: 0.0556 - acc: 0.9777"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "resnet50_obj.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出\n",
    "resnet50_predict = resnet50_obj.predict(test_data)\n",
    "resnet50_predict = resnet50_predict.clip(min=0.005, max=0.995)\n",
    "resnet50_predict = resnet50_predict.flatten(order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果\n",
    "submission = pd.DataFrame(data = {'id':(np.arange(len(test_data))+1), 'label': resnet50_predict})\n",
    "submission.to_csv('submission_resnet50.csv',index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
